{
  "created_at": "2023-08-07T07:12:48.587433Z",
  "error": "cuDNN error: CUDNN_STATUS_INTERNAL_ERROR\nYou can try to repro this exception using the following code snippet. If that doesn't trigger the error, please include your original repro script when reporting this issue.\n\nimport torch\ntorch.backends.cuda.matmul.allow_tf32 = False\ntorch.backends.cudnn.benchmark = True\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.allow_tf32 = True\ndata = torch.randn([8, 1280, 16, 16], dtype=torch.half, device='cuda', requires_grad=True)\nnet = torch.nn.Conv2d(1280, 1280, kernel_size=[1, 1], padding=[0, 0], stride=[1, 1], dilation=[1, 1], groups=1)\nnet = net.cuda().half()\nout = net(data)\nout.backward(torch.randn_like(out))\ntorch.cuda.synchronize()\n\nConvolutionParams \n    memory_format = Contiguous\n    data_type = CUDNN_DATA_HALF\n    padding = [0, 0, 0]\n    stride = [1, 1, 0]\n    dilation = [1, 1, 0]\n    groups = 1\n    deterministic = false\n    allow_tf32 = true\ninput: TensorDescriptor 0x55812b095940\n    type = CUDNN_DATA_HALF\n    nbDims = 4\n    dimA = 8, 1280, 16, 16, \n    strideA = 327680, 256, 16, 1, \noutput: TensorDescriptor 0x558094066a60\n    type = CUDNN_DATA_HALF\n    nbDims = 4\n    dimA = 8, 1280, 16, 16, \n    strideA = 327680, 256, 16, 1, \nweight: FilterDescriptor 0x5580b0f4c080\n    type = CUDNN_DATA_HALF\n    tensor_format = CUDNN_TENSOR_NCHW\n    nbDims = 4\n    dimA = 1280, 1280, 1, 1, \nPointer addresses: \n    input: 0x7f514fc00000\n    output: 0x7f5150100000\n    weight: 0x7f5238fa0000",
  "id": "l3hwoabbj2xb73kbnalbcjn44q",
  "input": {
    "class_prompt": "a photo of a person",
    "instance_data": "https://replicate.delivery/pbxt/JJ7VltK8fjbtUEb3RhKXqueAnPR5bg4PotaL6kZYnuYrQ6ip/data.zip",
    "instance_prompt": "a photo of a cjw person",
    "max_train_steps": 2000
  },
  "logs": "/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/accelerate/accelerator.py:179: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.\nwarnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/diffusers/utils/deprecation_utils.py:35: FutureWarning: The configuration file of the unet has set the default `sample_size` to smaller than 64 which seems highly unlikely .If you're checkpoint is a fine-tuned version of any of the following:\n- CompVis/stable-diffusion-v1-4\n- CompVis/stable-diffusion-v1-3\n- CompVis/stable-diffusion-v1-2\n- CompVis/stable-diffusion-v1-1\n- runwayml/stable-diffusion-v1-5\n- runwayml/stable-diffusion-inpainting\nyou should change 'sample_size' to 64 in the configuration file. Please make sure to update the config accordingly as leaving `sample_size=32` in the config might lead to incorrect results in future versions. If you have downloaded this checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull request for the `unet/config.json` file\nwarnings.warn(warning + message, FutureWarning)\nGenerating class images:   0%|          | 0/13 [00:00<?, ?it/s]\nGenerating class images:   0%|          | 0/13 [00:03<?, ?it/s]\nTraceback (most recent call last):\nFile \"/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/cog/server/worker.py\", line 217, in _predict\nresult = predict(**payload)\nFile \"/src/predictor.py\", line 289, in predict\nmain(args)\nFile \"/src/dreambooth.py\", line 592, in main\nimages = pipeline(example[\"prompt\"]).images\nFile \"/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\nreturn func(*args, **kwargs)\nFile \"/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 532, in __call__\nnoise_pred = self.unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\nFile \"/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\nreturn forward_call(*input, **kwargs)\nFile \"/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/diffusers/models/unet_2d_condition.py\", line 341, in forward\nsample, res_samples = downsample_block(\nFile \"/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\nreturn forward_call(*input, **kwargs)\nFile \"/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py\", line 644, in forward\nhidden_states = attn(hidden_states, encoder_hidden_states=encoder_hidden_states).sample\nFile \"/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\nreturn forward_call(*input, **kwargs)\nFile \"/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/diffusers/models/attention.py\", line 209, in forward\nhidden_states = self.proj_in(hidden_states)\nFile \"/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\nreturn forward_call(*input, **kwargs)\nFile \"/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 457, in forward\nreturn self._conv_forward(input, self.weight, self.bias)\nFile \"/root/.pyenv/versions/3.10.9/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 453, in _conv_forward\nreturn F.conv2d(input, weight, bias, self.stride,\nRuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR\nYou can try to repro this exception using the following code snippet. If that doesn't trigger the error, please include your original repro script when reporting this issue.\nimport torch\ntorch.backends.cuda.matmul.allow_tf32 = False\ntorch.backends.cudnn.benchmark = True\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.allow_tf32 = True\ndata = torch.randn([8, 1280, 16, 16], dtype=torch.half, device='cuda', requires_grad=True)\nnet = torch.nn.Conv2d(1280, 1280, kernel_size=[1, 1], padding=[0, 0], stride=[1, 1], dilation=[1, 1], groups=1)\nnet = net.cuda().half()\nout = net(data)\nout.backward(torch.randn_like(out))\ntorch.cuda.synchronize()\nConvolutionParams\nmemory_format = Contiguous\ndata_type = CUDNN_DATA_HALF\npadding = [0, 0, 0]\nstride = [1, 1, 0]\ndilation = [1, 1, 0]\ngroups = 1\ndeterministic = false\nallow_tf32 = true\ninput: TensorDescriptor 0x55812b095940\ntype = CUDNN_DATA_HALF\nnbDims = 4\ndimA = 8, 1280, 16, 16,\nstrideA = 327680, 256, 16, 1,\noutput: TensorDescriptor 0x558094066a60\ntype = CUDNN_DATA_HALF\nnbDims = 4\ndimA = 8, 1280, 16, 16,\nstrideA = 327680, 256, 16, 1,\nweight: FilterDescriptor 0x5580b0f4c080\ntype = CUDNN_DATA_HALF\ntensor_format = CUDNN_TENSOR_NCHW\nnbDims = 4\ndimA = 1280, 1280, 1, 1,\nPointer addresses:\ninput: 0x7f514fc00000\noutput: 0x7f5150100000\nweight: 0x7f5238fa0000",
  "metrics": { "predict_time": 9.311838 },
  "model": "holma91/dbtest",
  "notes": null,
  "status": "failed",
  "webhook_completed": "https://example.com/dreambooth-webhook",
  "version": null
}
